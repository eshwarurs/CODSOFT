# -*- coding: utf-8 -*-
"""codsoft

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZfdmB5j_HPDV6LuSjW_0g99Af2wPxBN_
"""



# Import necessary libraries
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer  # Import the imputer

# Load the training dataset
data_train = pd.read_csv('fraudTrain.csv')

# Load the testing dataset
data_test = pd.read_csv('fraudTest.csv')

# Handle missing values in the target variable 'is_fraud'
data_train['is_fraud'].fillna(0, inplace=True)  # Filling missing values with 0
data_test['is_fraud'].fillna(0, inplace=True)   # Filling missing values with 0

# Specify the features (X) and the target variable (y)
features = [
    'amt', 'lat', 'long', 'city_pop', 'unix_time',
    # Add other columns as needed
]

X_train = data_train[features]
X_test = data_test[features]

y_train = data_train['is_fraud']
y_test = data_test['is_fraud']

# Impute missing values in the feature columns (X_train and X_test)
imputer = SimpleImputer(strategy='mean')  # You can change the strategy as needed
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Train a Random Forest classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Predict on the test set
y_pred = clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_report_str = classification_report(y_test, y_pred)

# Print the results
print("Accuracy:", accuracy)
print("\nClassification Report:")
print(classification_report_str)

# Import necessary libraries
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Load the dataset
data = pd.read_csv('Churn_Modelling.csv')

# Encode categorical variables (e.g., 'Geography' and 'Gender') as numerical
label_encoder = LabelEncoder()
data['Geography'] = label_encoder.fit_transform(data['Geography'])
data['Gender'] = label_encoder.fit_transform(data['Gender'])

# Specify features (X) and target variable (y)
features = ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',
            'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']

X = data[features]
y = data['Exited']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest classifier
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# Make predictions
y_pred = clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_report_str = classification_report(y_test, y_pred)

# Print the results
print("Accuracy:", accuracy)
print("\nClassification Report:")
print(classification_report_str)

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
data = pd.read_csv('spam.csv', encoding='latin-1')

# Convert labels to binary values (0 for legitimate, 1 for spam)
data['v1'] = data['v1'].map({'ham': 0, 'spam': 1})

# Split the dataset into features (X) and labels (y)
X = data['v2']
y = data['v1']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the TF-IDF vectorizer
tfidf_vectorizer = TfidfVectorizer(stop_words='english')

# Fit and transform the training data
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Transform the testing data
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Initialize and train a Multinomial Naive Bayes classifier
naive_bayes_classifier = MultinomialNB()
naive_bayes_classifier.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = naive_bayes_classifier.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_report_str = classification_report(y_test, y_pred)

# Print the results
print("Accuracy:", accuracy)
print("\nClassification Report:")
print(classification_report_str)